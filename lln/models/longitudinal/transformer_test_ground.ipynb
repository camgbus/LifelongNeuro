{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of subjects and time points\n",
    "num_subjects = 100\n",
    "time_points = ['T1', 'T2', 'T3']\n",
    "\n",
    "# Function to categorize blood pressure\n",
    "def categorize_bp(systolic_bp):\n",
    "    if systolic_bp < 120:\n",
    "        return 0 #'Normal'\n",
    "    elif 120 <= systolic_bp <= 129:\n",
    "        return 1 #'Elevated'\n",
    "    else:\n",
    "        return 2 #'Hypertension'\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "data = {\n",
    "    'SubjectID': np.repeat([f'subject_{i:03}' for i in range(1, num_subjects + 1)], len(time_points)),\n",
    "    'TimePoint': time_points * num_subjects,\n",
    "    'SystolicBP': np.random.randint(110, 150, num_subjects * len(time_points)),\n",
    "    'DiastolicBP': np.random.randint(70, 90, num_subjects * len(time_points))\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_longitudinal = pd.DataFrame(data)\n",
    "\n",
    "# Filter T3 time points to add the BP category\n",
    "df_longitudinal['BPCategory'] = df_longitudinal['SystolicBP'].apply(categorize_bp)\n",
    "\n",
    "# Calculate the number of rows to remove, to test whether it is robust to missing rows\n",
    "#num_rows_to_remove = int(len(df_longitudinal) * 0.2)\n",
    "#df_longitudinal = df_longitudinal.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#df_longitudinal = df_longitudinal.iloc[num_rows_to_remove:]\n",
    "\n",
    "all_subjects = list(df_longitudinal['SubjectID'].unique())\n",
    "train_subjects, test_subjects = all_subjects[:80], all_subjects[80:]\n",
    "df_train = df_longitudinal[df_longitudinal['SubjectID'].isin(train_subjects)]\n",
    "df_test = df_longitudinal[df_longitudinal['SubjectID'].isin(test_subjects)]\n",
    "\n",
    "dataset_path = \"C:\\\\Users\\\\camgonza\\\\Box\\\\Camila Gonzalez's Files\\\\Data\\\\NCANDA\\\\NCANDA_experiments\\\\long_testground\"\n",
    "df_longitudinal.to_csv(dataset_path + \"/df_longitudinal.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lln.data.pytorch.get_dataset import LongDataset\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lln.models.longitudinal.Transformer import FeatureTransformer\n",
    "from lln.training.LongitudinalTrainer import LongitudinalTrainer\n",
    "\n",
    "input_dim = 2  # Number of features (systolic BP)\n",
    "dim_model = 64 # Number of features in the hidden state\n",
    "nr_layers = 3  # Number of LSTM layers\n",
    "num_heads = 4  # Number of attention heads\n",
    "dim_feedforward = 256  # Feedforward network size\n",
    "seq_to_seq = True\n",
    "see_future = True\n",
    "output_dim = 3  # Number of output classes (Normal, Elevated, Hypertension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subject_001', 'subject_002', 'subject_003', 'subject_004', 'subject_005', 'subject_006', 'subject_007', 'subject_008', 'subject_009', 'subject_010', 'subject_011', 'subject_012', 'subject_013', 'subject_014', 'subject_015', 'subject_016', 'subject_017', 'subject_018', 'subject_019', 'subject_020', 'subject_021', 'subject_022', 'subject_023', 'subject_024', 'subject_025', 'subject_026', 'subject_027', 'subject_028', 'subject_029', 'subject_030', 'subject_031', 'subject_032', 'subject_033', 'subject_034', 'subject_035', 'subject_036', 'subject_037', 'subject_038', 'subject_039', 'subject_040', 'subject_041', 'subject_042', 'subject_043', 'subject_044', 'subject_045', 'subject_046', 'subject_047', 'subject_048', 'subject_049', 'subject_050', 'subject_051', 'subject_052', 'subject_053', 'subject_054', 'subject_055', 'subject_056', 'subject_057', 'subject_058', 'subject_059', 'subject_060', 'subject_061', 'subject_062', 'subject_063', 'subject_064', 'subject_065', 'subject_066', 'subject_067', 'subject_068', 'subject_069', 'subject_070', 'subject_071', 'subject_072', 'subject_073', 'subject_074', 'subject_075', 'subject_076', 'subject_077', 'subject_078', 'subject_079', 'subject_080']\n",
      "['subject_081', 'subject_082', 'subject_083', 'subject_084', 'subject_085', 'subject_086', 'subject_087', 'subject_088', 'subject_089', 'subject_090', 'subject_091', 'subject_092', 'subject_093', 'subject_094', 'subject_095', 'subject_096', 'subject_097', 'subject_098', 'subject_099', 'subject_100']\n"
     ]
    }
   ],
   "source": [
    "# Define PyTorch datasets and dataloaders\n",
    "datasets = OrderedDict([('Train', LongDataset(df_train, feature_cols=['SystolicBP', 'DiastolicBP'], target_col='BPCategory', seq_to_seq=seq_to_seq, id_col='SubjectID', seq_col='TimePoint', timepoints=['T1', 'T2', 'T3'])),\n",
    "            ('Test', LongDataset(df_test, feature_cols=['SystolicBP', 'DiastolicBP'], target_col='BPCategory', seq_to_seq=seq_to_seq, id_col='SubjectID', seq_col='TimePoint', timepoints=['T1', 'T2', 'T3']))])\n",
    "print(datasets['Train'].subjects)\n",
    "print(datasets['Test'].subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: torch.Size([10, 3, 2])\n",
      "Shape of y: torch.Size([10, 3]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 10\n",
    "dataloaders = OrderedDict([(dataset_name, DataLoader(dataset, batch_size=batch_size, shuffle=True))\n",
    "    for dataset_name, dataset in datasets.items()])\n",
    "for X, y in dataloaders['Train']:\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureTransformer(\n",
      "  (input_projection): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder_input_projection): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (transformer_decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_projection): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "save_path = \"C:\\\\Users\\\\camgonza\\\\Box\\\\Camila Gonzalez's Files\\\\Data\\\\NCANDA\\\\NCANDA_experiments\\\\long_testground\\\\models\"\n",
    "model = FeatureTransformer(input_dim, dim_model, num_heads, dim_feedforward, nr_layers, output_dim=output_dim, dropout=0.1, seq_to_seq=seq_to_seq, see_future=see_future, save_path=save_path)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and trainer\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "trainer_path = \"C:\\\\Users\\\\camgonza\\\\Box\\\\Camila Gonzalez's Files\\\\Data\\\\NCANDA\\\\NCANDA_experiments\\\\long_testground\\\\trainer\"\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainer = LongitudinalTrainer(trainer_path, 'cpu', optimizer, loss_f, seq_to_seq=seq_to_seq, labels=[\"Normal\", \"Elevated\", \"Hypertension\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nr_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mnr_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnr_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarting_from_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mprint_loss_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnr_epochs\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnr_epochs\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnr_epochs\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\camgonza\\desktop\\code\\lifelongneuro\\lln\\training\\Trainer.py:48\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, model, train_dataloader, eval_dataloaders, nr_epochs, starting_from_epoch, print_loss_every, eval_every, export_every, verbose)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(starting_from_epoch, starting_from_epoch\u001b[38;5;241m+\u001b[39mnr_epochs)):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# Run evaluation before executing the epoch\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 48\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_ix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m%\u001b[39m export_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport(model, state_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(t), verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\users\\camgonza\\desktop\\code\\lifelongneuro\\lln\\training\\LongitudinalTrainer.py:43\u001b[0m, in \u001b[0;36mLongitudinalTrainer.eval\u001b[1;34m(self, model, eval_dataloaders, epoch_ix, verbose)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     42\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 43\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_f(pred, y)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     45\u001b[0m     targets \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(y\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\camgonza\\AppData\\Local\\anaconda3\\envs\\lln\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\users\\camgonza\\desktop\\code\\lifelongneuro\\lln\\models\\longitudinal\\Transformer.py:85\u001b[0m, in \u001b[0;36mFeatureTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m     82\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder(src, mask\u001b[38;5;241m=\u001b[39msrc_mask, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_to_seq:\n\u001b[1;32m---> 85\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder_input_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(tgt)\n\u001b[0;32m     87\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_decoder(tgt, memory, tgt_mask\u001b[38;5;241m=\u001b[39mtgt_mask, memory_mask\u001b[38;5;241m=\u001b[39mmemory_mask, \n\u001b[0;32m     88\u001b[0m         tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_key_padding_mask, memory_key_padding_mask\u001b[38;5;241m=\u001b[39mmemory_key_padding_mask)\n",
      "File \u001b[1;32mc:\\Users\\camgonza\\AppData\\Local\\anaconda3\\envs\\lln\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\camgonza\\AppData\\Local\\anaconda3\\envs\\lln\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "nr_epochs = 100\n",
    "trainer.train(model, dataloaders['Train'], dataloaders, \n",
    "              nr_epochs=nr_epochs, starting_from_epoch=0,\n",
    "              print_loss_every=int(nr_epochs/10), eval_every=int(nr_epochs/10), export_every=int(nr_epochs/5), verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
